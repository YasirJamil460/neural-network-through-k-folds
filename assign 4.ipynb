{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Combine training and test sets for 5-fold cross-validation\n",
        "X = np.concatenate((X_train, X_test))\n",
        "y = np.concatenate((y_train, y_test))\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "X = X / 255.0\n",
        "\n",
        "# Reshape data for the dense layers (flatten each 28x28 image to 784)\n",
        "X = X.reshape(len(X), 28 * 28)\n"
      ],
      "metadata": {
        "id": "YrYK2NPuctc4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validate(loss_function, one_hot_encode=False):\n",
        "    \"\"\"\n",
        "    Perform 5-fold cross-validation using the specified loss function.\n",
        "\n",
        "    Args:\n",
        "    - loss_function (str): Loss function to use for training.\n",
        "    - one_hot_encode (bool): Whether to one-hot encode the labels (needed for KLD).\n",
        "\n",
        "    Returns:\n",
        "    - dict: Metrics including training and validation accuracy/loss and time taken for each fold.\n",
        "    \"\"\"\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    metrics = {\"training_acc\": [], \"validation_acc\": [], \"training_loss\": [], \"validation_loss\": [], \"time\": []}\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X):\n",
        "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
        "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
        "\n",
        "        if one_hot_encode:\n",
        "            y_train_fold = tf.keras.utils.to_categorical(y_train_fold, num_classes=10)\n",
        "            y_val_fold = tf.keras.utils.to_categorical(y_val_fold, num_classes=10)\n",
        "\n",
        "        # Define the model architecture as per Assignment 4 requirements\n",
        "        model = keras.Sequential([\n",
        "            keras.layers.Dense(16, input_shape=(784,), activation='sigmoid'),\n",
        "            keras.layers.Dense(16, activation='sigmoid'),\n",
        "            keras.layers.Dense(10, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        # Compile the model with the specified loss function\n",
        "        model.compile(optimizer='adam', loss=loss_function, metrics=['accuracy'])\n",
        "\n",
        "        # Train the model and record the time taken\n",
        "        start_time = time.time()\n",
        "        model.fit(X_train_fold, y_train_fold, epochs=5, verbose=0)\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Evaluate the model on training and validation data\n",
        "        training_loss, training_acc = model.evaluate(X_train_fold, y_train_fold, verbose=0)\n",
        "        validation_loss, validation_acc = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "\n",
        "        # Record metrics\n",
        "        metrics[\"training_acc\"].append(training_acc)\n",
        "        metrics[\"validation_acc\"].append(validation_acc)\n",
        "        metrics[\"training_loss\"].append(training_loss)\n",
        "        metrics[\"validation_loss\"].append(validation_loss)\n",
        "        metrics[\"time\"].append(end_time - start_time)\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "9OpF7fPKcXnl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform 5-fold cross-validation for sparse_categorical_crossentropy\n",
        "sparse_metrics = cross_validate('sparse_categorical_crossentropy', one_hot_encode=False)\n",
        "\n",
        "# Perform 5-fold cross-validation for categorical_crossentropy with one-hot encoding\n",
        "kld_metrics = cross_validate('kld', one_hot_encode=True)\n"
      ],
      "metadata": {
        "id": "w1_NiRb6chtZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def display_results(metrics, loss_function_name):\n",
        "    \"\"\"\n",
        "    Display cross-validation results in a tabular format.\n",
        "\n",
        "    Args:\n",
        "    - metrics (dict): Cross-validation metrics.\n",
        "    - loss_function_name (str): Name of the loss function for the results.\n",
        "    \"\"\"\n",
        "    print(f\"Results for {loss_function_name}:\")\n",
        "    print(\"{:<15} {:<15} {:<15} {:<15} {:<15} {:<15}\".format(\n",
        "        \"Fold\", \"Train Acc\", \"Val Acc\", \"Train Loss\", \"Val Loss\", \"Time Taken\"\n",
        "    ))\n",
        "\n",
        "    # Print results for each fold\n",
        "    for i in range(5):\n",
        "        print(\"{:<15} {:<15.4f} {:<15.4f} {:<15.4f} {:<15.4f} {:<15.4f}\".format(\n",
        "            i + 1,\n",
        "            metrics[\"training_acc\"][i],\n",
        "            metrics[\"validation_acc\"][i],\n",
        "            metrics[\"training_loss\"][i],\n",
        "            metrics[\"validation_loss\"][i],\n",
        "            metrics[\"time\"][i]\n",
        "        ))\n",
        "\n",
        "    # Calculate and display average and standard deviation for accuracy and loss\n",
        "    avg_train_acc = np.mean(metrics[\"training_acc\"])\n",
        "    avg_val_acc = np.mean(metrics[\"validation_acc\"])\n",
        "    avg_train_loss = np.mean(metrics[\"training_loss\"])\n",
        "    avg_val_loss = np.mean(metrics[\"validation_loss\"])\n",
        "    avg_time = np.mean(metrics[\"time\"])\n",
        "\n",
        "    std_train_acc = np.std(metrics[\"training_acc\"])\n",
        "    std_val_acc = np.std(metrics[\"validation_acc\"])\n",
        "    std_train_loss = np.std(metrics[\"training_loss\"])\n",
        "    std_val_loss = np.std(metrics[\"validation_loss\"])\n",
        "    std_time = np.std(metrics[\"time\"])\n",
        "\n",
        "    # Print averages and standard deviations\n",
        "    print(\"\\nAverage:\")\n",
        "    print(\"{:<15} {:<15.4f} {:<15.4f} {:<15.4f} {:<15.4f} {:<15.4f}\".format(\n",
        "        \"Average\", avg_train_acc, avg_val_acc, avg_train_loss, avg_val_loss, avg_time\n",
        "    ))\n",
        "    print(\"\\nStandard Deviation:\")\n",
        "    print(\"{:<15} {:<15.4f} {:<15.4f} {:<15.4f} {:<15.4f} {:<15.4f}\".format(\n",
        "        \"Std Dev\", std_train_acc, std_val_acc, std_train_loss, std_val_loss, std_time\n",
        "    ))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Example usage:\n",
        "# Display results for sparse_categorical_crossentropy\n",
        "display_results(sparse_metrics, \"Sparse Categorical Crossentropy\")\n",
        "\n",
        "# Display results for kullback_leibler_divergence\n",
        "display_results(kld_metrics, \"Kullback-Leibler Divergence\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWGHsr9TcnYo",
        "outputId": "18fe1bff-9405-4e45-c50b-da6c21da5828"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Sparse Categorical Crossentropy:\n",
            "Fold            Train Acc       Val Acc         Train Loss      Val Loss        Time Taken     \n",
            "1               0.9376          0.9256          0.2199          0.2524          16.7379        \n",
            "2               0.9425          0.9346          0.2023          0.2264          16.3957        \n",
            "3               0.9406          0.9303          0.2096          0.2393          16.4421        \n",
            "4               0.9409          0.9327          0.2103          0.2366          16.1845        \n",
            "5               0.9389          0.9318          0.2163          0.2408          16.5117        \n",
            "\n",
            "Average:\n",
            "Average         0.9401          0.9310          0.2117          0.2391          16.4544        \n",
            "\n",
            "Standard Deviation:\n",
            "Std Dev         0.0017          0.0030          0.0061          0.0083          0.1789         \n",
            "\n",
            "\n",
            "Results for Kullback-Leibler Divergence:\n",
            "Fold            Train Acc       Val Acc         Train Loss      Val Loss        Time Taken     \n",
            "1               0.9413          0.9314          0.2114          0.2414          14.4260        \n",
            "2               0.9405          0.9326          0.2020          0.2330          14.7525        \n",
            "3               0.9432          0.9334          0.2042          0.2335          14.9027        \n",
            "4               0.9382          0.9328          0.2108          0.2364          16.0225        \n",
            "5               0.9337          0.9260          0.2298          0.2556          14.5633        \n",
            "\n",
            "Average:\n",
            "Average         0.9394          0.9312          0.2116          0.2400          14.9334        \n",
            "\n",
            "Standard Deviation:\n",
            "Std Dev         0.0032          0.0027          0.0098          0.0084          0.5682         \n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}